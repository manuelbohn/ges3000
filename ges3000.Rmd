---
title             : "Children spontaneously recreate core properties of language in a new modality"
shorttitle        : "Language in a new modality"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
  - name          : ""
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : ""
  - id            : "2"
    institution   : ""

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["library.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, echo = FALSE}
library(papaja)
library(tidyverse)
library(ggthemes)
library(langcog)
library(lme4)
library(exactRankTests)
```
# Introduction

Structured language is thought of as a lengthy process of cultural/geentic evolution. Here we show that children (largely without formal schooling) spontaneously re-create some if the core properties of langugage in a new modality: they invent referential signals, converge on a way of signalling, produce more arbitrary signals over time and create syntactical constructions to describe more complex scenarios. We take this to be evidence that structured communication is a natural/direct consequence of how humans communicate.

Children learn language at incredible speed. Adults scaffold learning process. However, during language evolution, no such scaffolding was there. Communicative partners on "on equal terms" created and shaped emerging communication system. Here we approximate this siutation by studying how dyads of young children create a new communication system. We find that children spontaneously creat communication systems that share many of the core properties of language (referentiality, conventionality, arbitrariness/efficiency, grammar ...). 

Grammar: expressivity = need to express complex ideas - requires either very complex holistic signals or structured utterances

children spontaneously create structured and holistic symbols that then have differetn survival rates when passed on to next generation? Focus in our task was on expressivity but structure nevertheless arises, even when it's not necessary.

sign language emergence in home sign - even if signs are not learned from parents, parents structure interactions so that children can make themselves easily understood and are also willing and able to make additional inferences about children's intended meaning. 

Two disparate literatures, one looking at how children without a language model create their own structured communication system and the the other looking at how communication changes and structure emerges over repeated interactions in adults. Here we show that children who have already mastered one communication system, quickly switch modalities to create a new one. Furthermore, we show that these newly created communication systems already possess some of the core properties of language.

Lit: 
Clark tangram studies: Clark, H. H., & Wilkes-Gibbs, D. (1986). Referring as a collaborative process. Cognition, 22(1), 1-39.

word order: Gibson, E., Piantadosi, S. T., Brink, K., Bergen, L., Lim, E., & Saxe, R. (2013). A Noisy-Channel Account of Crosslinguistic Word-Order Variation. Psychological Science, 24(7), 1079â€“1088. http://doi.org/10.1177/0956797612463705

Newport adults, some time in the 80s

Kirby, S., Tamariz, M., Cornish, H., & Smith, K. (2015). Compression and communication in the cultural evolution of linguistic structure. Cognition, 141, 87-102.

Garrod, S., Fay, N., Lee, J., Oberlander, J., & MacLeod, T. (2007). Foundations of representation: where might graphical symbol systems come from?. Cognitive science, 31(6), 961-987.

Goldin-Meadow, S., & Mylander, C. (1998). Spontaneous sign systems created by deaf children in two cultures. Nature, 391(6664), 279.

Language evolution in the laboratory
Author links open overlay panelThomas C.Scott-PhillipsSimonKirby

Word Meanings Evolve to Selectively PreserveDistinctions on Salient DimensionsCatriona Silvey, Simon Kirby, Kenny Smith


https://languagecreationlab.uconn.edu/wp-content/uploads/sites/644/2014/03/brentari_coppola_wires_2012.pdf

# Discussion

Difference between leanring a language and creating one.
Some aspects seem to come for free (convergence and drift) but others (establishing reference) are more challenging (developmental differences?). Same true for grammar.

Limitations:

Very "samll world", reference was established, porbably, by excluding alternatives. GEsture fit more with one rather than the other picture. Cannot estimate the role of common ground in establishing communication here. Howeve,r common ground is alwqys a part of communication (in adults and development). Convention formation is, to some extend, grounding a certain way of referring and expecting all memebers of a group to adhere to it. Done locally here within a dyad, therefore the general processes that follow are probably be the same.


# General setup and procedure

All studies used the same general setup and procedure. We established an audio-video connection between two separate rooms within a child laboratory. In each room a Panasonic XX video camera was mounted on a tripod which was placed behind a XX" XXX TV screen. Each camera captured an area in front of the TV, which was marked with black tape on the floor. Children were encouraged to stay within the marked area to ensure that their partner could see them. A black cross in the center of the area marked children's starting position in each trial. A little fence was used in each room to prevent participants from approaching the TV and/or the camera. The connection was established through DVI cables that went from the camera in one room to the TV in the other room and vice versa. External microphones were plugged into the cameras to capture children's speech. The direct connection between camera and TV made sure that that participants could interact in a smooth and contingent way. One of the rooms was assigned to be the Production Room (PR) and the other the Comprehension Room (CR). A third camera was put in the back of the CR, capturing the child as well as the TV screen. This was an additional measure to ensure that we could link the two videos recorded by the two main cameras.

The two rooms were located on the same hallway. When stepping outside, the experimenters (E1 and E2) could easily talk to one another and coordinate their actions. In each room, we installed a picture board. Importantly, the picture boards were never visible on the TV in the other room. In part 1, the picture board was a wooden, turn-able wheel with five triangular pictures, showing 1) a hammering hand, 2) a female person combing her hair, 3) a boy on a bicycle, 4) a woman eating with a fork and 5) nothing (a white piece of paper, see Figure X). On top of the wheel was a little red arrow that was used to indicate which picture children had to communicate to their partner. A picture was selected by turning the wheel until the picture was on top underneath the arrow. In part 2, the board was a larger, rectangular board. The pictures differed from experiment to experiment and are therefore described later in more detail. In part 2, a sticky red paper arrow was used to indicate a picture.

In the beginning of each trial, E1 was with the child in PR (Production Child - PC) and E2 with the child in CR (Comprehension Child - CC). The general trial structure in all experiments went as follows: Children were first asked to take their starting position (facing away from the board towards the wall). Next, E1 selected a picture in PR. On a visual signal from E1, both Es said "ready, set, go" and left the room. Children were now allowed to turn around. The task of the child in PR was to communicate the content of the selected picture to the child in CR. The child in CR made a choice by selecting a picture on her board and knocking on the door. Thereupon, Es opened the doors, E2 told E1 across the hallway which picture had been selected in the CR and E1 checked if this was the same picture as in the PR. If the pictures were different, children were told that it didn't work out this time but that they could try again in the next trial. If the pictures were the same, children received a marble, which they collected in a tube. At the end of the study, children exchanged the marbles for stickers. 

All children started with a training phase in which the video as well as the audio connection was still intact. In the beginning of the training phase, children and Es entered their respective rooms. They greeted each other through the TV and established that they could only be seen by their partner when they were inside the marked area. Next, E1 and PC "discovered" the picture board. E1 encouraged PC to ask CC if they also had a picture board in their room. When CC confirmed that they did, PC went through all pictures (including the empty one) and asked CC if had the same kind of picture on her board. This established common ground between children that they had the same pictures on their board. Es did not provide label for the pictures but let children label them. Es used whatever label children used to refer to the pictures. Next, E1 suggested that they could play a fun game in which children could win marbles. Children were told that the game involves PC communicating to CC which picture was selected on her board and CC selecting the same picture. This marked the beginning of the training phase in which the audio connection was still working. PC could therefore simply tell CC which picture was selected. The training familiarized children with the structure of the game. During training, each picture was selected once. 

After the last training trial, children were told that they could play the game in a different way to make it more fun. Children and Es left the room and met in the hallway. Next, one E went into each room and cut the audio connection by turning off the volume at each TV. To strengthen the impression that the other one could not longer hear what was being said as well as to prevent children from trying to communicate via shouting, low instrumental Jazz music was played in both rooms (Chet Baker - "Out of nowhere"). If children shouted nevertheless, the experimenters asked them to lower their voice. When children re-entered the room, each E drew her child's attention to the music and encouraged her to ask the other child whether she also heard the music. This way children discovered that they could no longer hear each other. After stating that they could not hear anybody from the other room, children and Es left the room to meet in the hallway. There they confirmed that they could not hear each other when in the room. E1 asked the children if they wanted to play the game nevertheless and also reminded them of the game's structure. Gestures as an alternative means of communication was never mentioned. Next, children went into their respective room and the first test trial started.

In each test trial, children had one minute to establish communication. If they remained passive, E1 entered the PR and prompted PC to use iconic gestures in three steps. Between prompts, she waited for 30s to see if the child would start gesturing. As first prompt, E1 said:"[CCs name] can't hear you, but she can see you, maybe you can *show* (German: zeigen) it to her". The second prompt was: "She can't hear you but she can see you, look we can wave to her, maybe you can *demonstrate* (German: vormachen) it to her". As the final prompt, she said: "Oh, I have an idea ... this way it could work" and started to perform an iconic gesture depicting the action corresponding to the selected picture. 

Describe gestrues demonstrated by E. 

As soon as the child also used the gesture, E1 left the room and the trial continued as described above. During prompting, E2 entered CR and encouraged CC to attend to the TV.

## General note on analysis

Data and analysis scripts can be found online at ``htps://github.com/manuelbohn/ges3000``. To improve readability, we only report a small set of statistics in the text itself (estimates, standard errors and p-values for models and p-values for other tests). For additional information we ask the reader to directly run the code and look at the model outputs. For all analysis, we used R [@R-base] and for models we used the function glmer of the lme4 package [@R-lme4] with maximal random effect structures. Non-significant interaction terms were removed from models and p-values were based on likelihood ratio tests [@dobson2008introduction] which were computed via the function ``drop1``.

# Part 1: Production and comprehension

# Part 1.1.1: Spontaneous production of gestures by 4- and 6-year-old children in a peer context 

In the following, we describe the methodological details and deviations from the general protocol for each part of the studies.

## Participants
```{r part 1-1-1 data, include = FALSE}
d1 <- read.csv(file="data/pt1_prod_up_comp.csv") %>% 
  filter(block == "Spontaneous") %>%
  na.omit(prompts) # remove trials without response

```

We tested 24 same sex, same age dyads of four (mean age within dyad = `r round(mean(d1$mage[d1$age=="M48"]),2)`, range = `r round(range(d1$mage[d1$age=="M48"])[1],2)` to `r round(range(d1$mage[d1$age=="M48"])[2],2)`) and six year-old children (mean age within dyad = `r round(mean(d1$mage[d1$age=="M72"]),2)`, range = `r round(range(d1$mage[d1$age=="M72"])[1],2)` to `r round(range(d1$mage[d1$age=="M72"])[2],2)`), with 12 dyads per age group, six male and six female. Children came from an ethnically homogeneous, mid-sized German city (approx. 550.000 inhabitants, median income â‚¬1254 per month as of 2015), were mostly mono-lingual and had mixed socio-economic background. They were recruited from a database of children whose parents volunteered to take part in studies on child development. Data collection took place between April and September 2016. XX additional dyads were excluded because ...

## Design and procedure
The test phase following the training was divided into two parts, "spontaneous" and "uptake". Children were first tested with all pictures except the empty picture. We reasoned that including the empty picture from the beginning might discourage children from establishing communication through gestures. The empty picture was introduced after each other picture had been selected at least once (twice for six-year-olds). The first trial of the spontaneous phase assessed whether children would discover the idea to use gestures to communicate independently. If the PR remained passive for one minute in the first test trial, instead of receiving prompts, children switched rooms and the former CR got a chance to spontaneously start gesturing. If the new PR remained passive for another minute, E1 started prompting. The three trials following the first trial, each with a new picture, assessed whether children would transfer the idea of using gestures. For the second part, uptake, children switched rooms and roles. In this part, all pictures were used right away.

Six-year-olds received a total of 30 test trials, 20 in spontaneous and 10 in uptake. Pilot testing suggested that this was too long for the younger age group and so four-year-olds received a total of 19 test trials, 14 in spontaneous and 5 in uptake. The order in which pictures were selected was randomized with the constraint that each picture was selected once before another picture could be selected again. 

For most children, the intermediate prompts were not helpful and we therefore do not differentiate between them in the analysis. We only analyse whether a dyad received a prompt or not.

## Results and discussion

```{r part 1-1-1, include = FALSE}
# Do 4yo need more prompts in trial 1 than 6yo?
d1.t <- d1 %>%  
  filter(blocktrial == 1) %>%
  group_by(age, dyad_id) %>%
  summarise(prompts = sum(prompts)) %>%
  mutate(prompts = ifelse(prompts > 0,1,0)) %>%
  summarize(prompts = list(prompts)) %>%
  spread(age,prompts) %>%
  mutate(sum4 = sum(unlist(M48)),
         sum6 = sum(unlist(M72)),
         stat = wilcox.exact(unlist(M48),unlist(M72))$statistic,
         p_value = wilcox.exact(unlist(M48),unlist(M72))$p.value)%>%
  select(sum4,sum6,stat,p_value)

# Do children get better with trials? 
d1.m <- d1 %>%
  filter(blocktrial < 5) %>%
  mutate(blocktrial = scale(as.numeric(blocktrial), center = TRUE, scale=TRUE))%>%
  group_by(blocktrial,dyad_id,age) %>%
  summarise(prompts = sum(prompts))%>%
  mutate(prompts = ifelse(prompts > 0,1,0))
  
# non-significant interaction has been removed  
m1 <- glmer(prompts ~ blocktrial + age + (blocktrial|dyad_id), family = binomial, data = d1.m, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
```


```{r plot1, echo = FALSE, fig.cap="\\label{fig:plot1}Spontaneous gesture production without prompts in the first trials of the test phase. Each of the first four trials involved a different picture."}
# plot for dyads producing gestures (instead of for dyads needing prompts)
d1.p <- d1 %>%  
  mutate(prompts = ifelse(prompts > 0,1,0)) %>%
  mutate(Age = ifelse(age == "M48","4yo","6yo")) %>%
  filter(blocktrial<5) %>%
  group_by(Age, blocktrial) %>%
  summarise(prompts = sum(prompts)) %>%
  mutate(prompts = 12 - prompts)


ggplot(d1.p, 
       aes(x = blocktrial, y = prompts, col = Age)) +
  geom_line(aes(group= Age))+
  geom_point(aes(group= Age))+
  theme_few() + 
  scale_y_continuous(name = "Dyads Spontaneously Producing Gestures", limits = c(0,12), breaks = c(0,2,4,6,8,10,12))+
  scale_x_continuous(name = "Trial", breaks = c(1:4))+
  theme_few() +
  scale_colour_solarized()
```

Except for a single, unsuccesful attempt to use lip-reading, all children produced gestures.

Describe some gesture variants produced by children

First we looked at the production of iconic gestures in the beginning of the test phase. Figure \ref{fig:plot1} shows that the majority of six-year-olds spontaneously produced gestures already in trial 1, more so compared to four-year-olds (trial 1: *p* = `r sub('^(-)?0[.]', '\\1.', round(d1.t$p_value, 3))`, Wilcoxon test; trial 1-4: $\beta$ = `r round(summary(m1)$coefficients[3,1], 2)`, se = `r round(summary(m1)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m1,test="Chi")[3,4], 3))`, model: `` prompts ~ age + trial + (trial|dyad_id)``). Even though four-year-olds initially only produced gestures after receiving prompts, they needed fewer prompts in later trials, showing that they transferred the idea of iconically depicting an referent to new pictures (main effect of trial: $\beta$ = `r round(summary(m1)$coefficients[2,1], 2)`, se = `r round(summary(m1)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m1,test="Chi")[2,4], 3))`). Thus, while both age groups successfully adopted a novel means of communication (iconic gestures) to coordinate, six-year-olds did so spontaneously while four-year-olds needed an initial hint.  

# Part 1.1.2: Spontaneous production of gestures by 3- and 4-year-olds when communicating with an adult.

Part 1.1.2 follows up on 1.1.1 developmentally. We repeated the initial phase of the first study with three- and four-year-olds to investigate if and how younger children would be able to substitute speech for iconic gestures. The main focus of the study was on gesture production and so we tested children with an adult partner to streamline the procedure. We also added more pictures to prolong the phase in which children could transfer the idea of using iconic gestures to new pictures. 

## Participants
```{r part 1-1-2 data, include = FALSE}
d2 <- read.csv(file="data/pt1_trans_3_4.csv") 
```

Twelve three-year-olds (mean = `r round(mean(d2$mage[d2$age=="m36"]),2)`, range = `r round(range(d2$mage[d2$age=="m36"])[1],2)` to `r round(range(d2$mage[d2$age=="m36"])[2],2)`) and 12 four-year-olds (mean = `r round(mean(d2$mage[d2$age=="m48"]),2)`, range = `r round(range(d2$mage[d2$age=="m48"])[1],2)` to `r round(range(d2$mage[d2$age=="m48"])[1],2)`) participated in the study. Recruitment was the same as in 1.1.1. Xx additional children were excluded because ... . Data was collected between January and March 2017.

## Design and procedure

The procedure was the same as for part 1.1.1 with the following changes: Instead of testing peer dyads, children were tested with E2 as the CC. We removed the empty picture and used two different ones instead, one depicting a duck and the second one depicting a deer (see Fig. X). All children received 12 trials, two trials with each picture. In the first phase (transfer), children started with the four pictures from part 1.1.1 in a randomized order followed by the two new pictures, also in a randomized order. In the second phase (imitation), pictures were repeated in the same way. Since there was no CC, there was no uptake phase. Pilot testing showed that three-year-olds felt uncomfortable alone in the room. Therefore E1 remained in the room throughout a trial but pretended to be working on something else while the child was communicating with E2. We dropped the intermediate prompts and E1 directly presented an iconic gesture as the solution if the child remained passive for more than 1 minute.

## Results and discussion
```{r part 1-1-2, include = FALSE}
# do 4yo transfer more rapidly compared to 3yo?
# 3-way interaction: slope for trial is steeper in 4yo only in transfer but not in imitation
# maximal converging model

d2.m <- d2 %>%
  mutate(trial = scale(as.numeric(blocktrial), center = TRUE, scale=TRUE))

m2 <- glmer(prompts ~ block*age*blocktrial + (blocktrial + block||id) + (1|stimulus) , family = binomial, data = d2.m,
        control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

summary(m2)

drop1(m2,test="Chi")
```


```{r plot2, echo = FALSE, fig.cap="\\label{fig:plot2}Spontaneous gesture production without prompts in the first trials of the transfer phase. Each of the first six trials involved a different picture and pictures were repeated in the imitation phase."}
# plot 
d2.p <- d2 %>%
  mutate(Age = ifelse(age == "m36","3yo","4yo")) %>%
  mutate(block = relevel(block, ref = "Transfer")) %>%
  group_by(Age,trial, blocktrial,block) %>%
  summarise(prompts = sum(prompts))%>%
  mutate(prompts = 12 - prompts)

ggplot(d2.p, 
       aes(x = blocktrial, y = prompts, col = Age)) +
  geom_line(aes(group= Age))+
  geom_point(aes(group= Age))+
  facet_grid(~block)+
  theme_few() + 
  scale_y_continuous(name = "Dyads Spontaneously Producing Gestures", limits = c(0,12), breaks = c(0,2,4,6,8,10,12))+
  scale_x_continuous(name = "Trial", breaks = c(1:6))+
  scale_colour_manual(name="Age",
                      labels=c("3yo", "4yo"), values=c("#859900", "#dc322f"))

```

Figure \ref{fig:plot2} shows the production of iconic gestures in the transfer and imitation phase. Like in 1.1.1 four-year-olds did not spontaneously create iconic gestures in trial 1 but rapidly transferred the idea of doing so to new pictures. Three-year-olds relied mostly on prompts throughout the transfer phase. In the imitation phase, at least half of the three-year-olds produced gestures independently. We confirmed the differential rate of transfer statistically by fitting a model (``prompts ~ block * age * trial + (trial + block||id) + (1|stimulus)``) finding a significant three-way-interaction, suggesting a steeper slope for trial for four-year-olds in the transfer but not the imitation phase ($\beta$ = `r round(summary(m2)$coefficients[8,1], 2)`, se = `r round(summary(m2)$coefficients[8,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m2,test="Chi")[2,4], 3))`). 

Summarizing the results for production, we may say that six-year-olds independently create iconic gestures as an alternative means of communication when spoken language cannot be used. Four-year-olds initially struggle but rapidly transfer the idea of using gestures to new instances. Three-year-olds rarely create their own gestures but mostly rely on imitating gestures they were taught by others. 

# Part 1.2: Uptake

Next, we investigated gesture production during uptake. That is, whether children, who previously played the role of CC, would spontaneously produce gestures when they play the role of the PC. For this analysis we return to the dataset from 1.1.1.

## Participants, design and procedure

See 1.1.1. 

## Results and discussion
```{r part 1-2, include = FALSE}
# prompts needed during uptake phase
d3 <- read.csv(file="data/pt1_prod_up_comp.csv") %>% 
  filter(block == "Uptake") %>%
  na.omit(prompts)

d3.t <- d3 %>%  
  filter(blocktrial == 1) %>%
  group_by(age, dyad_id) %>%
  summarise(prompts = sum(prompts)) %>%
  mutate(prompts = ifelse(prompts > 0,1,0)) %>%
  summarize(prompts = list(prompts)) %>%
  spread(age,prompts) %>%
  mutate(sum4 = sum(unlist(M48)),
         sum6 = sum(unlist(M72)),
         stat = wilcox.exact(unlist(M48),unlist(M72))$statistic,
         p_value = wilcox.exact(unlist(M48),unlist(M72))$p.value)%>%
  select(sum4,sum6,stat,p_value)

#comparing prompts in spontaneous to prompts in uptake
d3.t2 <- read.csv(file="data/pt1_prod_up_comp.csv") %>%  
  filter(blocktrial == 1 & age =="M48") %>%
  group_by(block, dyad_id) %>%
  summarise(prompts = sum(prompts)) %>%
  mutate(prompts = ifelse(prompts > 0,1,0)) %>%
  summarize(prompts = list(prompts)) %>%
  spread(block,prompts) %>%
  mutate(sumS = sum(unlist(Spontaneous)),
         sumU = sum(unlist(Uptake)),
         stat = wilcox.exact(unlist(Spontaneous),unlist(Uptake))$statistic,
         p_value = wilcox.exact(unlist(Spontaneous),unlist(Uptake))$p.value)%>%
  select(sumS,sumU,stat,p_value)

```

```{r plot3, echo = FALSE, fig.cap="\\label{fig:plot2}Spontaneous gesture production without prompts in the first trials of the uptake part. Here the production child was previously the comprehension child during the spontaneous part. Each trial involved a different picture, including the empty one."}
# plot
d3.p <- d3 %>%  
  mutate(prompts = ifelse(prompts > 0,1,0)) %>%
  mutate(Age = ifelse(age == "M48","4yo","6yo")) %>%
  filter(blocktrial<6) %>%
  group_by(Age, blocktrial) %>%
  summarise(prompts = sum(prompts))%>%
  mutate(prompts = 12 - prompts)

# plot
ggplot(d3.p, 
       aes(x = blocktrial, y = prompts, col = Age)) +
  geom_line(aes(group= Age))+
  geom_point(aes(group= Age))+
  theme_few() + 
  scale_y_continuous(name = "Dyads Spontaneously Producing Gestures", limits = c(0,12), breaks = c(0,2,4,6,8,10,12))+
  scale_x_continuous(name = "Trial", breaks = c(1:5))+
  scale_colour_solarized()

```

Figure \ref{fig:plot3} shows that all six-year-olds and also most of the four year-olds spontaneously produced gestures. Statistically, there was no difference between the age groups at trial 1 (*p* = `r sub('^(-)?0[.]', '\\1.', round(d3.t$p_value, 3))`, Wilcoxon test). Furthermore, fewer four-year-olds needed prompts in trial 1 during uptake compared to spontaneous (*p* = `r sub('^(-)?0[.]', '\\1.', round(d3.t2$p_value, 3))`). These results show that once one child established a way of referring to the pictures the other child easily picked it up. 

# Part 1.3: Comprehension

Next we looked at whether the gestures that children produced were understood by their partners. We did not have any specific hypothesis about differences between items and we therefore do not analyse them separately. Nevertheless, to give an impression of the variability in the data set, plots show the overall results as well as the results by stimulus.

## Participants, design and procedure

See 1.1.1. We excluded trials with the empty picture. These trials will be analysed separately in the next section. 

## Results and discussion
```{r pt 1-3, include = FALSE}
# comprehension by phase excluding empty picture
d4 <- read.csv(file="data/pt1_prod_up_comp.csv") %>%
  filter(stimulus != "Nothing") %>%
  mutate(block = ifelse(block=="Uptake","Uptake","Spontaneous"))%>%
  mutate(Age = ifelse(age == "M48","4yo","6yo"))

# are 6yo better than 4yo at comprehension
# 6yo got more trials, for comparison we select those trials for 6yo that 4yo also got.
d4.m <- d4 %>%
  filter(ifelse(block=="Uptake",blocktrial<6,blocktrial<15)) %>%
  mutate(trial = scale(as.numeric(blocktrial), center = TRUE, scale=TRUE))

# non-sognificant higher order interactions removed
# maximal converging model (model with trial as random slope within stimulus yields problems when doing case wise deletions)
m4 <- glmer(comp ~ age+block+trial+ (trial+block|dyad_id) + (block|stimulus), family = binomial, data = d4.m,
        control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

summary(m4)

drop1(m4,test="Chi")
```

Table \ref{tab:table1} and Figure \ref{fig:plot4} show that that the gestures produced by the PC were generally understood by the CC in both age groups. To compare comprehension across age groups over trials and in blocks, we fit the following model: `comp ~ age + block + trial + (trial + block | dyad_id) + (block | stimulus)`. Because six-year-olds received more trials in spontaneous and uptake (see 1.1.1), we removed all trials that this age group got  beyond the number that four-year-olds got for this comparison. We also removed trials with the empty picture, which we analysed separately. Comprehension improved with trial ($\beta$ = `r round(summary(m4)$coefficients[4,1], 2)`, se = `r round(summary(m4)$coefficients[4,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m4,test="Chi")[4,4], 3))`) and was also slightly better in uptake compared to spontaneous ($\beta$ = `r round(summary(m4)$coefficients[3,1], 2)`, se = `r round(summary(m4)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m4,test="Chi")[3,4], 3))`). There was no difference between age groups ($\beta$ = `r round(summary(m4)$coefficients[2,1], 2)`, se = `r round(summary(m4)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m4,test="Chi")[2,4], 3))`). This shows that children generally depicted the content of the pictures in a way that was comprehensible to their partner.
```{r table1, results = "asis"}
# Comparing comprehension against chance (25% correct)
t4 <- d4 %>%
  group_by(Age, block, dyad_id)%>%
  summarise(comp = mean(comp))%>%
  summarise(comp = list(comp)) %>%
  group_by(Age, block) %>%
  mutate(df= t.test(unlist(comp), mu = 0.25)$parameter,
         mean = mean(unlist(comp)),
         t_value = t.test(unlist(comp), mu = 0.25)$statistic,
         p_value = t.test(unlist(comp), mu = 0.25)$p.value) %>%
  select(Age, block ,mean,df,t_value,p_value)


apa_table(t4,
            caption = "Gesture comprehension compared to chance.",
          note = "Statistics are based on two-tailed one sample t-tests with data aggregated for each dyad. Trials with empty pictures were excluded, hence we chose a more conservative comparison level of .25.")
```

```{r plot4, echo = FALSE, fig.cap="\\label{fig:plot2}Proportion correct picture chosen by the CC by part and item. First row shows overall comprehension. Dotted line indicates performance expected by chance. Error bars are 95% confidence intervals based on non-parametric bootstraps."}
# plot per age group and phase
d4.p2 <- read.csv(file="data/pt1_prod_up_comp.csv") %>%
  mutate(block = ifelse(block=="Uptake","Uptake","Spontaneous"))%>%
  mutate(Age = ifelse(age == "M48","4yo","6yo")) %>%
  group_by(Age, stimulus, block, dyad_id)%>%
  summarise(comp = mean(comp))

d4.p3 <- d4.p2 %>%
  multi_boot_standard(col = "comp")

d4.p4 <- d4.p2 %>%
  group_by(Age, block, dyad_id)%>%
  summarise(comp = mean(comp)) %>%
  multi_boot_standard(col = "comp")%>%
  mutate(stimulus = "Overall")

ggplot() +
  geom_jitter(data = d4.p2, aes(x = stimulus, y = comp, col = Age, alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = d4.p3,aes(x = stimulus, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .5), size = 0.5, alpha = .5) +
  geom_pointrange(data = d4.p4,aes(x = stimulus, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .5), size = 0.75) +
  geom_hline(yintercept = 0.25, lty=2)+
  guides(alpha = F)+
  facet_grid(~block)+
  labs(x="Picture")+
  scale_y_continuous(name = "Proportion Correct", limits = c(-0.05,1.05))+
  theme_few() + 
  scale_colour_solarized()+ coord_flip()
```

# Part 1.4: Abstract concepts (empty picture)

As mentioned above, we analysed production and comprehension separately for trials in which the empty picture was selected. In contrast to the other pictures, the empty picture did not show an action that could be turned into an iconic gesture. Children therefore had to find a different way to establish reference. On the comprehension side, children could select the empty picture either because PC's gesture successfully communicated the "emptiness" of the picture or because the gesture they saw did not match any of the other pictures. The latter was possible because we introduced the empty picture only after all other pictures had been selected at least once.

## Participants, design and procedure

see 1.1.1.

## Results and discussion

Describe the gestures being used for nothing. Depicting "nothing", doing nothing, pointing to white things. some of these gestures were resulted from little conversations in which the CC would produce gestures for some of the other pictures, "asking" the PC if it was this one.

```{r part 1-4, include = FALSE}
#### Production
# prompts per age group and phase
d5 <- read.csv(file="data/pt1_prod_up_comp.csv") %>% 
  filter(stimulus == "Nothing") %>%
  mutate(block = ifelse(block=="Uptake","Uptake","Spontaneous"))%>%
  mutate(Age = ifelse(age == "M48","4yo","6yo")) %>%
  na.omit(prompts)

# descriptives for production (plot not informative) and tests
# do 4yo need more prompts compared to 6yo?
d5.t1 <- d5 %>%
  group_by(age, block, dyad_id) %>%
  summarise(prompts = sum(prompts)) %>%
  mutate(prompts = ifelse(prompts > 0,1,0)) %>%
  summarize(prompts = list(prompts)) %>%
  spread(age,prompts) %>%
  group_by(block) %>%
  mutate(sum4 = sum(unlist(M48)),
         sum6 = sum(unlist(M72)),
         stat = wilcox.exact(unlist(M48),unlist(M72))$statistic,
         p_value = wilcox.exact(unlist(M48),unlist(M72))$p.value)%>%
  select(block,sum4,sum6,stat,p_value)

### Comprehension 
#comparing against chance per age group and phase
d5.t2 <- d5 %>%
  group_by(Age, block, dyad_id)%>%
  summarise(comp = mean(comp))%>%
  summarise(comp = list(comp)) %>%
  group_by(Age,block) %>%
    mutate(mean = mean(unlist(comp)),
           stat = wilcox.exact(unlist(comp), mu = 0.25)$statistic,
           p_value = wilcox.exact(unlist(comp), mu = 0.25)$p.value) %>%
    select(Age,block,mean,stat,p_value)

# are 6yo better than 4yo at comprehension
d5.m <- d5 %>%
  filter(ifelse(block=="Uptake",blocktrial<6,blocktrial<15))

#model does not converge with interaction
m5 <- glmer(comp ~ age+block + (1|dyad_id), family = binomial, data = d5.m,
        control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

summary(m5)

drop1(m5,test="Chi")

```

Both age groups sponteneously produced gestures for the empty picture. Six-year-olds did not need prompts in any of the two parts. Four dyads of four-year-olds needed prompts in spontaneous and two did so in uptake. Statistically, there was no difference between age groups regarding the number of prompts (spontaneous: *p* = `r sub('^(-)?0[.]', '\\1.', round(d5.t1$p_value[1], 3))`, uptake: *p* = `r sub('^(-)?0[.]', '\\1.', round(d5.t1$p_value[2], 3))`; Wilcoxon test). 
The second row in Figure \ref{fig:plot4} shows how well the gestures were understood by the CC. In general, children chose the correct picture above chance (all *p* < .01), except for four-year-olds in spontaneous (*p* = `r sub('^(-)?0[.]', '\\1.', round(d5.t2$p_value[1], 3))`, Wilcoxon test). To compare performance between age groups and blocks, we again dropped all trials that six-year-olds got more than four-year-olds and fit a model to the data (`comp ~ age + block + (1 | dyad_id)`). Rate of comprehension was higher for six-year-olds ($\beta$ = `r round(summary(m5)$coefficients[2,1], 2)`, se = `r round(summary(m5)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m5,test="Chi")[2,4], 3))`) and during the uptake part ($\beta$ = `r round(summary(m5)$coefficients[3,1], 2)`, se = `r round(summary(m5)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m5,test="Chi")[3,4], 3))`). Taken together, both age groups produced gestures for the empty picture. These gestures were immediately understood in the older age group and during the uptake part also in the younger one. 

# Part 2: Convergence

In part 1 we saw that children switched to a new modality when spoken language was no longer an option. They created iconic gestures which successfully communicated the content of the picture to their partner. In the second part, we inverstigate whether children would use the same kind of gesture for a given picture. To do this we compared the gestures produced in the spontaneous and the uptake part. We hypothesized that children within a dyad would use more similar gestures compared to children from different dyads. In general, there are many different ways to iconically depict a picture (see part 1.1.1 for some variants created by children). Children within a dyad should be more similar because the PC in the uptake part (the former CC) can simply imitate the gesture she saw during the spontaneous part. The degree to which we can detect similarity due to imitation is limited by the variability in how children initially depict the picture. For example, if many children independently decide to depict the comb by stroking a hand across the head, similarity will be high across dyads and similarity within dyads due to imitatio will be hard to detect. 

## Participants

We used the videos of children producing gestures during part 1. Twelve adult raters, unfamiliar with the study design and procedure, judged the similarity of gestures within dyads.

## Design and Procedure

For each dyad we selected the video of the last gesture for a picture from the PC during spontaneous and the first gesture for the same picture from the PC (former CC) during uptake. That is, we chose the two depictions of the same picture by the two children that were closest in time. We used E-Prime (version 2.0.10.356) to set-up the rating procedure. On each trial, the rater was shown a sample video on top of the screen (see Figure XX) and two comparison videos on the bottom, one on the left and one in the right. The sample showed a child during the sponteneous part. One of the comparison videos showed the child from the *same* dyad during uptake whereas the other video showed a child of the same age and sex from a *different* dyad, also during uptake, also producing a gesture for the same picture. On each trial, the comparison video was randomly selected from the pool of suitable videos. Furthermore, the position of the comparison videos on the screen (left or right) was randomly determined. Raters could watch and rewatch each video multiple times. Each video was numbered (sample video was always nr. 1) and raters were asked: "Which video is more similar to 1". They made a choice by pressing the respective number on the keyboard. Raters went through the videos in blocks. Each block consisted of all videos from a given age and sex for a particular picture. The order of blocks was randomized across raters. We only used videos corresponding to trials in which the child produced a gesture without prompts. This resulted in a total number of 97 sample videos.

## Results and discussion.
```{r part 1-5, include = FALSE}
d6 <- read.csv(file="data/pt1_convergence.csv") %>% 
  mutate(Age = ifelse(age == "M48","4yo","6yo"))

# Do raters choose the gesture from the same dyad above chance in both age groups?
d6.t <- d6 %>%
  group_by(Age, rater)%>%
  summarise(corr = mean(corr))%>%
  summarise(corr = list(corr)) %>%
  group_by(Age) %>%
  mutate(mean = mean(unlist(corr)),
         df= t.test(unlist(corr), mu = 0.5)$parameter,
         t_value = t.test(unlist(corr), mu = 0.5)$statistic,
         p_value = t.test(unlist(corr), mu = 0.5)$p.value) %>%
  select(Age,mean,df,t_value,p_value)

d6.m <- d6  %>%
  mutate(trial = scale(as.numeric(trial), center = TRUE, scale=TRUE))

# model 
m6 <- glmer(corr ~ age + (age | rater) + (1 | video), family = binomial, data = d6.m, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# summary
summary(m6)
# p values
drop1(m6, test = "Chi")

### select only videos with gestures for which children did not receive a prompt

ex <- read.csv(file="data/pt1_prod_up_comp.csv") %>% 
  filter(prompts > 2)%>%
  select(video) %>%
  mutate(video = as.character(video))

d6.no.prompt <- filter(d6, !video %in% ex$video)

d6.m2 <- d6.no.prompt  %>%
  mutate(trial = scale(as.numeric(trial), center = TRUE, scale=TRUE))

# model 
m6.2 <- glmer(corr ~ age + (age| rater) + (1 | video), family = binomial, data = d6.m2, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# summary
summary(m6.2)
# p values
drop1(m6.2, test = "Chi")

  
```

```{r plot5, echo = FALSE, fig.cap="\\label{fig:plot2}Proportion with which raters judged the video from the same dyad to be more similar, overall and by item. Dotted line indicates performance expected by chance. Error bars are 95% confidence intervals based on non-parametric bootstraps."}
# plot per age group and stimulus
d6.p2 <- d6 %>%
  group_by(Age, stimulus, rater)%>%
  summarise(corr = mean(corr))

d6.p3 <- d6.p2 %>%
  multi_boot_standard(col = "corr")


d6.p4 <- d6 %>%
  group_by(Age,rater) %>%
  summarise(corr = mean(corr)) %>%
  multi_boot_standard(col = "corr") %>%
  mutate(stimulus = "Overall")


ggplot() +
  geom_jitter(data = d6.p2, aes(x = stimulus, y = corr, col = Age, alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = d6.p3,aes(x = stimulus, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = .5, alpha = .8) + 
  geom_pointrange(data = d6.p4,aes(x = stimulus, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 1)+
  geom_hline(yintercept = 0.5, lty=2)+
  xlab("Picture")+
  guides(alpha = F)+
  scale_y_continuous(name = "Proportion Gesture from Same Dyad Chosen", limits = c(-0.05,1.05))+
  theme_few() + 
  scale_colour_solarized()+ coord_flip()

```

Figure \ref{fig:plot5} shows how often the video from the same dyad was rated to be more similar to the sample video. For both age groups, raters chose the video from the same dyad above chance (both *p* < .001). In direct comparison, corresponding videos were chosen slightly more often for six- compared to four-year-olds ($\beta$ = `r round(summary(m6)$coefficients[2,1], 2)`, se = `r round(summary(m6)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m6,test="Chi")[2,4], 3))`, model: `corr ~ age + (age | rater) + (1 | video)`). This difference might follow from the different rate of spontaneous production found in part 1. Six-year-olds mostly created gestures independently, probably resulting in more different gestures between dyads. Four-year-olds on the other hand, relied more often on prompts from the experimenter. Since most prompting resulted in the experimenter showing the child an iconic gesture, four-year-olds' gestures were more similar because many of them were imitations of the experimenter's gesture. To adress this empirically, we subsetted the data and excluded all videos showing gestures which were produced following a direct demonstration by the experimenter. In contrast to the hypothesis laid out above, excluding prompted gestures augmented rather than weakened the difference between age groups ($\beta$ = `r round(summary(m6.2)$coefficients[2,1], 2)`, se = `r round(summary(m6.2)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m6.2,test="Chi")[2,4], 3))`). Nevertheless, both age groups produced more similar gestures within than between dyads. 


# Part 3: Drift to arbitrary

Adult communicators streamline their communication over time by reducing the effort of each utterance. When using iconic lexical items, this usually results in a "drift to the arbitrary" with items gradually loosing their iconicty. In part 3 we investigated this drift to the arbitrary in children's production and comprehension of gestures.

In terms of production, we compared the first instance of a gesture for a picture to the last to see if children streamline their utterances over time. In terms of comprehension, we paired children with an adult who produced more and more abstract gestures over time.

# Part 3.1: Drift to arbitrary production

We used the videos recorded during part 1. However, because children only got up to five repititions of the same gesture (four-year-olds only up to 3) we invited children back into the lab on a second day and repeated the procedure with fewer pictures and more repetitions per gesture. On this second day, we paired children with an adult comprehension partner.

## Participants
```{r part 3 participants}
d7.participants <- read.csv(file="data/pt1_drift_day2_production.csv")
```

For the additional study, we invited half of the children (one from each dyad) who participated in part 1 on day 1 back to the lab on a second day. Three four-year-olds could not participate on the second day and were therefore replaced with new children. In sum, twelve four-year-olds (mean age = `r round(mean(d7.participants$age[d7.participants$age_group=="M48"]),2)`, range = `r round(range(d7.participants$age[d7.participants$age_group=="M48"])[1],2)` to `r round(range(d7.participants$age[d7.participants$age_group=="M48"])[2],2)`) and 12 six-year-olds (mean age = `r round(mean(d7.participants$age[d7.participants$age_group=="M72"]),2)`, range = `r round(range(d7.participants$age[d7.participants$age_group=="M72"])[2],2)`) participated in the study.

We presented the videos from day 1 and 2 to twelve adult raters, who were unfamiliar with the study design and procedure. They were asked to rate how abstract and effortful gestures were. 

## Design and Procedure

For the data collection on day 2, we made the following changes to the procedure compared to day 1. We used E2 as  comprehension partner. Instead of a warm-up phase with sound, children received four training trials with the pictures from day 1, already without sound. Then the experimenter introduced the new pictures (deer, duck and fish, see Figure XX) that were used for the remainder of the session. Children received a total of 30 test trials, 10 with each picture. Order of pictures was randomized in blocks of six, that is, each picture was selected twice before another picture could be selected a third time. Children who did not participate on day 1, received additional training trials with sound and were prompted to use gestures if they did not do so spontaneously.

The rating procedure was simialr to the one used in part 2. For each child, we selected the first and the last gesture for a picture. That is, we used the two depictions for the same picture that were furthewst apart in time. From day 1, we only used gestures produced during spontaneous because four-year-olds only received one trial with each picture during uptake. Again, we used E-Prime (version 2.0.10.356) to set-up the rating procedure. On a trial, the rater was shown the two videos from a child with a given picture, one showing the first and the other showing the last gesture production (see Figure XX). The position of each video (left and right) was randomly determined. The two videos were numbered and raters could select them by pressing the corresponding number on the keyboard. On each trial, raters could watch and re-watch the videos as they liked. The first rating question was always "Which of the two gestures is more abstract?" and the second question was "Which of the two gestures is more effortful?". Before going throught the videos, raters read discriptions of what was meant by the two rating categories "abstract" and "effortful". We defined *abstract* as ... and *effortful* as .... 

Raters went through the videos in blocks. Each block consisted of all videos from a given age and sex for a particular picture. Raters were shown the picture that was used as stimulus for children in the beginning of each block. Order of blocks was randomized across raters. Like in part 2, we only used videos from trials in which the child produced the gestrue spontaneously. In total, there were 168 video pairs.

## Results and discussion
```{r part 3 production, include = FALSE}
d7 <- read.csv(file="data/pt1_drift_production.csv") %>% 
  mutate(Age = ifelse(age == "M48","4yo","6yo"))%>%
  filter(phase != "Uptake")  #filtering out uptake because 4yo only got 1 trial per stimulus in uptake

### influence of age and effort per day. 
# day 1
d7.m1 <- d7 %>%
  filter(day == "Day1")

m7.1 <- glmer(abs ~ age + effort + (age | rater) + (1 | video), family = binomial, data = d7.m1, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

summary(m7.1)

drop1(m7.1,test="Chi")

#day2
d7.m2 <- d7 %>%
  filter(day == "Day2")

m7.2 <- glmer(abs ~ age + effort + (age | rater) + (1 | video), family = binomial, data = d7.m2, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

summary(m7.2)

drop1(m7.2,test="Chi")

```


```{r table2, results = "asis"}

 # Do raters choose the later gesture as the more abstract one?
### t-tests against chance per age group and day
t7 <-d7 %>%
  group_by(Age, day, rater)%>%
  summarise(abs = mean(abs))%>%
  summarise(abs = list(abs)) %>%
  group_by(Age, day) %>%
  mutate(mean = mean(unlist(abs)),
         df= t.test(unlist(abs), mu = 0.5)$parameter,
         t_value = t.test(unlist(abs), mu = 0.5)$statistic,
         p_value = t.test(unlist(abs), mu = 0.5)$p.value) %>%
  select(Age,day,mean,df,t_value,p_value)


apa_table(t7,
            caption = "Abstractness ratings for gestures compared to chance.",
          note = "Statistics are based on two-tailed one sample t-tests with data aggregated for each rater. Chance comparison level is .5.")
```

```{r plot6, echo = FALSE, fig.cap="\\label{fig:plot2}Proportion with which raters judged the later gesture to be more abstract, overall by day and by item. Dotted line indicates performance expected by chance. Error bars are 95% confidence intervals based on non-parametric bootstraps."}
# plot per age group, phase, day and stimulus
d7.p2 <- d7 %>%
  group_by(Age, day, stimulus, rater)%>%
  summarise(abs = mean(abs))

d7.p3 <- d7.p2 %>%
  multi_boot_standard(col = "abs")


d7.p4 <- d7 %>%
  group_by(Age,day,rater) %>%
  summarise(abs = mean(abs)) %>%
  multi_boot_standard(col = "abs") %>%
  mutate(stimulus = "Overall")

ggplot() +
  geom_jitter(data = d7.p2, aes(x = stimulus, y = abs, col = Age, alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = d7.p3,aes(x = stimulus, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 0.5, alpha = .5) +
  geom_pointrange(data = d7.p4,aes(x = stimulus, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 1) +
  geom_hline(yintercept = 0.5, lty=2)+
  geom_vline(xintercept = 8.5, lty=1)+
  facet_grid(day~.,scales = "free_y", space = "free_y", drop = T)+
  guides(alpha = F)+
  scale_y_continuous(name = "Proportion Later Chosen", limits = c(-0.05,1.05))+
  xlab("Picture")+
  theme_few() + 
  scale_colour_solarized()+ 
  coord_flip()

```


```{r plot7, echo = FALSE, fig.cap="\\label{fig:plot2}Realtion between ratings of abstractness and effort for each day. Each dot represents the mean rating across raters for a video pair across. Regression lines show smoothed conditional means per age group with 95% confidence intervals."}

d7.p5 <- d7 %>%
  group_by(Age,day,video,stimulus) %>%
  summarise(abs = mean(abs),
            eff = mean(effort))

ggplot(data = d7.p5,aes(x = eff, y = abs, col = Age)) +
  geom_jitter(width = .02,height = .02, alpha = 0.7)+
  geom_smooth(method = "lm", se = T)+
  theme_few() +
  facet_wrap(~day)+
  xlab("Effort")+
  ylab("Abstractness")+
  #stat_cor(aes(col = Age), method = "pearson", label.x = 0.25,label.y = c(0,0.1),show.legend = F)+
  scale_colour_solarized()
```

We analysed the data for the two days separately because children were tested with different pictures. Table \ref{tab:table2} and Figure \ref{fig:plot6} show abstractness ratings compared to chance level. These results indicate that raters generally rated the later gestures to be more abstract. Figure \ref{fig:plot7} shows the relation between ratings for effort and abstractness.

To analyse the influence of age and effort on abstractness ratings, we fit the following model to the data from each day: `abs ~ age + effort + (age | rater) + (1 | video)`. For day 1, six-year-olds' later gestures were rated as more abstract more often compared to four-year-olds' ($\beta$ = `r round(summary(m7.1)$coefficients[2,1], 2)`, se = `r round(summary(m7.1)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m7.1,test="Chi")[2,4], 3))` ). Ratings of abstractness were strongly influenced by ratings of effort  ($\beta$ = `r round(summary(m7.1)$coefficients[3,1], 2)`, se = `r round(summary(m7.1)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m7.1,test="Chi")[3,4], 3))`). The age difference on day 1 might be due to the fact that six-year-olds received more trials with each picture on day 1. If this would be the case, the age difference should disappear on day 2 when both age groups received the same number of trials. Model results show that this was the case. On day 2, abstractness ratings were again strongly influenced by effort ($\beta$ = `r round(summary(m7.2)$coefficients[3,1], 2)`, se = `r round(summary(m7.2)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m7.2,test="Chi")[3,4], 3))`) but, in contrast to day 1, not by age ($\beta$ = `r round(summary(m7.2)$coefficients[2,1], 2)`, se = `r round(summary(m7.2)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m7.2,test="Chi")[2,4], 3))`). This pattern of results suggests that gestures became more abstract over time because children reduced the effort put into each depiction. The differential age effect further suggests that this is a function of the number of repetitions of each gesture.

# Part 3.2: Drift to arbitrary comprehension
```{r part 3 comprehension, include = FALSE}
d8 <- read.csv(file="data/pt1_drift_comprehension.csv") %>% 
  mutate(condition = ifelse(condition == "Abstract", "Abstract", "Iconic"))%>%
  mutate(condition = as.factor(condition))%>%
  mutate(Age = ifelse(age == "M48","4yo","6yo"))%>%
  mutate(phase = ifelse(phase == "test", "Test", "Control"))%>%
  mutate(phase= as.factor(phase))

# are children better in test compared to pretest when seeing abstract gestures?

# comparing test and pretest in iconic
d8.m1 <- d8  %>%
  filter(condition == "Iconic") %>%
  mutate(trial = scale(as.numeric(trial), center = TRUE, scale=TRUE))

m8.1 <- glmer(corr ~ age + phase + (1| id) + (1 | stimulus), family = binomial, data = d8.m1, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

# comparing test and pretest in abstract
d8.m2 <- d8  %>%
  filter(condition == "Abstract") %>%
  mutate(trial = scale(as.numeric(trial), center = TRUE, scale=TRUE))

m8.2 <- glmer(corr ~ age + phase + (trial | id) + (1 | stimulus), family = binomial, data = d8.m2, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

```

The previous section showed that children's gestures become more abstract over time, presumably because features of the initial depictions are dropped in order to reduce production effort. However, the gestures produced by children towards the end of the study were still highly iconic. We therefore investigated whether children would comprehend gestures that become more and more arbitrary over time, up to a point where they bear no direct iconic correspondence to the original picture. In order to comprehend them at the final stage, children had to keep track of each gesture as it was drifting towards the arbitrary. We contrasted performance in this condition with that of naive children who only saw the initial iconic depictions and the final abstract depictions but not the intermediate stages.

## Participants
We invited the other half of children per age group from day 1 back to the lab to participate in the drift to the arbitrary comprehension game. For the control condition, we recruited the same number of children per age group from local kindergartens. In total 24 four-year olds (mean age = `r round(mean(d8$i_age[d8$age=="M48"]),2)`, range = `r round(range(d8$i_age[d8$age=="M48"])[1],2)` to `r round(range(d8$i_age[d8$age=="M48"])[2],2)`) and 24 six-year-olds (mean age = `r round(mean(d8$i_age[d8$age=="M72"]),2)`, range = `r round(range(d8$i_age[d8$age=="M72"])[1],2)` to `r round(range(d8$i_age[d8$age=="M72"])[2],2)`) participated in the study. Three four-year-olds from day 1 could not come back on the second day and were therefore replaced with children who were naive to the procedure. Drop outs ...

## Design and Procedure
Data in the control condition was collected prior to the test condition. The logic behind this order was that we wanted to find abstract depictions for the pictures that children would not spontaneously understand. After showing that this was the case for one set of depictions, we tested whether children would understand these abstract forms if they had been tested on intermediate (more iconic) versions as well.

### Control
Children in the control condition were tested in a separate room in their kindergarten. Videos were played on a 15 inch laptop located on a table. The pictures to which the gestures corresponded were put on the table between child and laptop. They were the same as the ones that would be later used in the test condition (deer, duck and fish, same as in part 3.1). Children responded by pointing to or naming a picture. The videos showing the iconic and abstract depiction of each stimulus were pre-recorded in the same setup and involving the same experimenters as in the test condition. Children were instructed that they would see videos in which someone would depict one of the pictures in front of them and their task would be to guess which picture it was. As a warm-up, children received XX training trials with videos of iconic depictions of different pictures (XX, Tiger and Elephant). Criteria?????. Subsequently, children received six test trials: first three with abstract gestures and then three with iconic gestures (each time, one trial per picture). The order of stimuli was counterbalanced within trials of abstract and iconic depictions. Children received feedback???. Reliability . Abstract gestures corresponded to stage 5 and iconic to stage 1 depictions described below.

### Test
The general setup and procedure for the test condition (drift to the arbitrary) were similar to day 1. Children played the role of the CC but instead of a peer, they were paired with an adult production partner. As a warm-up, children received one trial with each of the pictures from day 1. Children who did not participate in day 1, received additional training trials with sound. After the warm-up, the pictures were changed to test pictures (deer, duck and fish, same as in the previous section). Each child received 30 trials. There were 5 stages of abstraction with six trials (two per picture) per stage. The order of pictures within each stage was randomized. Gestures became more abstract in that elements of the iconic depictions were removed and aspects of the original gestures were depicted in a different way. Sample videos can be found in the online repository. Below are detailed descriptions of the gestures from each stage for each picture:  

#### Deer 
Stage 1: The experimenter stretched out both arms over her had and spread her fingers as if depicting the deer's antlers. In addition she moved her upper body up and down and left and right. Stage 2: Both arms as well as fingers were stretched out next to the head but upper body was not moved. Stage 3: Instead of stretching out the arms, the experimenter depicted the distance that the arm/antler previously covered vertically next to her head. That is she put one arm, palm facing outwards close to her neck and her second arm, palm facing inwards, away from her head at the point where her outstretched arm previously ended. She did yo both on the left and the right side of her head. Stage 4: distance was only depicted on one side of the head. Stage 5: Instead of depicting the distance next to her head, the experimenter depicted the distance horizontally in front of her body (same hand position as in previous depiction). 
 
#### Duck
Stage 1: The experimenter bent her elbows, bringing her hands to her chest to depict the duck's wings. In addition she squatted, waddled around while moving her head and bent arms up and down to depict flapping the wings. Stage 2: Elbows were again bent and arms in front of chest. Arms and head were moved up and down to depict flapping of wings. Squatting and moving around were omitted. Stage 3: Experimenter bent her elbows but put put them down straight on the side (no flapping) while shrugging her shoulders. In addition eyebrows were moved up and down. Stage 4: No bending of arms, only shrugging shoulders and moving eye-brows up and down. Stage 5: Only the eyebrows were moved up and down. 

#### Fish
Stage 1: The experimenter put her palms together in front of her body, with arms stretched out and moved her arms in a curling motion left and right, while slowly moving forwards. In addition, she opened and closed her mouth. Stage 2: Only right arm was used to to make curling motion in front of body, mouth was still opened and closed. Moving forward was omitted. Stage 3: Opening and closing of mouth was omitted. Left arm was held horizontally in front of body (depicting a surface). Right arm made again the curling motion but ended with a little twist so that the right hand vertically hit the left hand (as if the fish (right hand) was jumping into the water (left hand)).Stage 4: Same as before but the curling motion of the right hand was omitted. The right hand was moved in a semi-circular motion to hit the left hand vertically. Stage 5: Only the left hand was held in front of the body. 

## Results and discussion
```{r table3, results = "asis"}
# Comparing comprehension against chance (25% correct)
### t-tests against chance per age group, day and phase
t8 <- d8 %>%
  group_by(Age,condition, phase, id)%>%
  summarise(corr = mean(corr))%>%
  summarise(corr = list(corr)) %>%
  group_by(Age,condition, phase) %>%
  mutate(mean = mean(unlist(corr)),
         df= t.test(unlist(corr), mu = 1/3)$parameter,
         t_value = t.test(unlist(corr), mu = 1/3)$statistic,
         p_value = t.test(unlist(corr), mu = 1/3)$p.value) %>%
  select(Age,phase,condition,mean,df,t_value,p_value) 


apa_table(t8,
            caption = "Gesture comprehension compared to chance for iconic and abstract gestures in test and control condition.",
          note = "Statistics are based on two-tailed one sample t-tests with data aggregated for each participant. Chance level = .33.")
```

```{r plot8, echo = FALSE, fig.cap="\\label{fig:plot2}Proportion correct picture chosen by age group and condition. Dotted line indicates performance expected by chance. Error bars are 95% confidence intervals based on non-parametric bootstraps."}
# plot per age group, condition and phase
d8.p <- d8 %>%
  mutate(condition = relevel(condition, ref = "Iconic")) %>%
  group_by(Age, condition, phase,id)%>%
  summarise(corr = mean(corr))

d8.p1 <- d8.p %>%
  multi_boot_standard(col = "corr")

ggplot() +
  geom_jitter(data = d8.p, aes(x = phase, y = corr, col = Age, alpha = .2), width = .1, height = .05)+
  geom_pointrange(data = d8.p1,aes(x = phase, y = mean, col = Age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 1) + 
  geom_hline(yintercept = 1/3, lty=2)+
  facet_grid(~condition)+
  guides(alpha = F)+
  xlab("Phase")+
  scale_y_continuous(name = "Proportion Correct", limits = c(-0.05,1.05))+
  theme_few() + 
  scale_colour_solarized()+
  coord_flip()
```

To have the same number of trials in test and control, we selected only children's first encounter with the abstract and iconic depictions of each picture in the test condition. Figure \ref{fig:plot8} summarizes performance in each condition, per age group and gesture type.  Both age groups performed above chance when seeing iconic gestures in the two conditions (see Table \ref{tab:table3}). Furthermore, when looking at iconic gestures, performance did not differ between control and test condition ($\beta$ = `r round(summary(m8.1)$coefficients[3,1], 2)`, se = `r round(summary(m8.1)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m8.1,test="Chi")[3,4], 3))`, model: `comp ~ age + block + ( block | id) + (block | stimulus)`). Six-year-olds performed better compared to four-year-olds ($\beta$ = `r round(summary(m8.1)$coefficients[2,1], 2)`, se = `r round(summary(m8.1)$coefficients[2,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m8.1,test="Chi")[2,4], 3))`).

Performance was at chance level for children in the control condition. As noted above, this served as a validation for abstract gestures. Importantly, the same gestures were comprehended  above chance in the test condition (Table \ref{tab:table3}). Furthermore children in the test outperformed children in the control condition on abstract gestures ($\beta$ = `r round(summary(m8.2)$coefficients[3,1], 2)`, se = `r round(summary(m8.2)$coefficients[3,2], 2)` *p* = `r sub('^(-)?0[.]', '\\1.', round(drop1(m8.2,test="Chi")[3,4], 3))`, model: `comp ~ age + block + ( block | id) + (block | stimulus)`). In sum, we found that children of both age groups successfully retained the meaning of a gesture when its form drifted from iconic to arbitrary. 

# Interim discussion

# Part 4: Grammatical constructions

```{r gram data}
#loading data

gram_data <- read.csv(file="data/pt2_data.csv") 

```



```{r}
gram_data %>% 
  group_by(condition, age)%>%
  summarise(n = length(unique(id)))


gram_data %>% 
  group_by(condition,age)%>%
  summarise(compr = mean(compr))

gram_data %>% 
  filter(predicate != "small",
         predicate != "static",
         predicate != "one")%>%
  group_by(predicate)%>%
  summarise(n = length(trial))

```

```{r}
# Gesture comprehension across conditions
gram_plot_compr_1 <- gram_data %>%
  group_by(age,condition,id)%>%
  summarise(compr = mean(compr))

gram_plot_compr_2 <- gram_plot_compr_1 %>%
  group_by(age,condition)%>%
  multi_boot_standard(col = "compr")



ggplot() +
  geom_jitter(data = gram_plot_compr_1, aes(x = condition, y = compr, col = age, alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = gram_plot_compr_2,aes(x = condition, y = mean, col = age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 0.7) +
  guides(alpha = F)+
  scale_y_continuous(name = "Proportion correct", limits = c(-0.05,1.05))+
  xlab("Condition")+
  ggtitle("Gesture comprehension by condition")+
  theme_few() +
  scale_colour_solarized() 


# Does diff help?

gram_plot_compr_3 <- gram_data %>%
  group_by(diff)%>%
  multi_boot_standard(col = "compr")

ggplot() +
  geom_pointrange(data = gram_plot_compr_3,aes(x = diff, y = mean,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 0.7) +
  guides(alpha = F)+
  scale_y_continuous(name = "Proportion correct", limits = c(-0.05,1.05))+
  xlab("Differentiate between ambiguous stimuli")+
  ggtitle("Gesture comprehension by differentiation")+
  theme_few() +
  scale_colour_solarized() 



# number of elements (for the elaborated)only for elaborated versions) and when differentiated

gram_plot_compr_4 <- gram_data %>%
  filter(diff == "yes",
         predicate != "small",
         predicate != "static",
         predicate != "one")%>%
  group_by(age,condition,id)%>%
  summarise(nr_elements = mean(nr_elements))

gram_plot_compr_5 <- gram_plot_compr_4 %>%
  group_by(age,condition)%>%
  multi_boot_standard(col = "nr_elements")

ggplot() +
  geom_jitter(data = gram_plot_compr_4, aes(x = condition, y = nr_elements, col = age, alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = gram_plot_compr_5,aes(x = condition, y = mean, col = age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 0.7) +
  guides(alpha = F)+
  scale_y_continuous(name = "Number of meaningful elements", limits = c(0,3))+
  xlab("Condition")+
  ggtitle("Nr. of elements by condition")+
  theme_few() +
  scale_colour_solarized() 


# proportion atomistic gestures

gram_plot_compr_6 <- gram_data %>%
   filter(diff == "yes",
        predicate != "small",
         predicate != "static",
         predicate != "one")%>%
  group_by(age,condition,id)%>%
  summarise(atom = mean(hol_or_atom))

gram_plot_compr_7 <- gram_plot_compr_6 %>%
  group_by(age,condition)%>%
  multi_boot_standard(col = "atom")

ggplot() +
  geom_jitter(data = gram_plot_compr_6, aes(x = condition, y = atom, col = age, alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = gram_plot_compr_7,aes(x = condition, y = mean, col = age,ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 0.7) +
  guides(alpha = F)+
  scale_y_continuous(name = "Proportion atomistic solutions", limits = c(-0.05,1.05))+
  xlab("Condition")+
  ggtitle("Atomistic solutions by condition")+
  theme_few() +
  scale_colour_solarized() 



```


```{r}

# word order

gram_plot_compr_8 <- gram_data %>%
  filter(hol_or_atom == 1)%>%
  mutate(lang_con_order = ifelse(order == "ps" | order == "so" | order == "spo", 1,0))%>%
  group_by(condition,id)%>%
  summarise(mean = mean(lang_con_order))

gram_plot_compr_9 <- gram_plot_compr_8 %>%
  group_by(condition)%>%
  multi_boot_standard(col = "mean")

ggplot() +
  geom_jitter(data = gram_plot_compr_8, aes(x = condition, y = mean, col = condition,  alpha = .2), width = .1,height = .05)+
  geom_pointrange(data = gram_plot_compr_9,aes(x = condition, y = mean,col = condition, ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = .5), size = 0.7) +
  guides(alpha = F, col = F)+
  scale_y_continuous(name = "Proportion German word order", limits = c(-0.05,1.05))+
  xlab("Condition")+
  ggtitle("Word order in comparison to first language by condition")+
  theme_few() +
  scale_colour_solarized() 

```




# Part 4.1: Size

## Participants

## Design and Procedure

## Results and discussion


# Part 4.2: Number

## Participants

## Design and Procedure

## Results and discussion


# Part 4.3: Movement

## Participants

## Design and Procedure

## Results and discussion


# Part 4.4: Transitive actions with two agents 

## Participants

## Design and Procedure

## Results and discussion


# Part 4.5: Transitive actions with three agents 

## Participants

## Design and Procedure

## Results and discussion


# Part 4 overall analysis

## Participants

## Design and Procedure

## Results and discussion






\newpage

# References
```{r create_r-references}
r_refs(file = "library.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
